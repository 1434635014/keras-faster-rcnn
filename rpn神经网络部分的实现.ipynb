{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.layers as KL\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(KL.BatchNormalization):\n",
    "    def call(self, inputs, training=None):\n",
    "        return super(self.__class__, self).call(inputs, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet网络 的building_block\n",
    "# filter：卷积核的通道数\n",
    "# block：block的标识\n",
    "def building_block(filters, block):\n",
    "    if block != 0:\n",
    "        stride = 1\n",
    "    else:\n",
    "        stride = 2\n",
    "    \n",
    "    def f(x):\n",
    "        y = KL.Conv2D(filters, (1,1), strides=stride)(x)  # 卷积核1×1\n",
    "        y = BatchNorm(axis=3)(y)\n",
    "        y = KL.Activation(\"relu\")(y)\n",
    "        \n",
    "        y = KL.Conv2D(filters, (3,3), padding=\"same\")(y)  # 卷积核1×1\n",
    "        y = BatchNorm(axis=3)(y)\n",
    "        y = KL.Activation(\"relu\")(y)\n",
    "        \n",
    "        y = KL.Conv2D(4 * filters, (1,1))(y)\n",
    "        y = BatchNorm(axis=3)(y)\n",
    "        \n",
    "        if block == 0:\n",
    "            shorcut = KL.Conv2D(4*filters, (1,1), strides=stride)(x)\n",
    "            shorcut = BatchNorm(axis=3)(shorcut)\n",
    "        else:\n",
    "            shorcut = x\n",
    "        y = KL.Add()([y, shorcut])\n",
    "        y = KL.Activation(\"relu\")(y)\n",
    "        return y\n",
    "    return f\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet网络\n",
    "def resNet_featureExtractor(inputs):\n",
    "    x = KL.Conv2D(64, (3,3), padding=\"same\")(inputs)\n",
    "    x = BatchNorm(axis=3)(x)\n",
    "    x = KL.Activation(\"relu\")(x)\n",
    "    \n",
    "    filters = 64   # 第一个卷积核的通道数\n",
    "    blocks = [4, 4, 4]    # buildblock的数量  change\n",
    "    \n",
    "    for i, block_num in enumerate(blocks):\n",
    "        for block_id in range(block_num):\n",
    "            x = building_block(filters, block_id)(x)\n",
    "        filters = filters * 2\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rpn_net(inputs, k):\n",
    "    shared_map = KL.Conv2D(256, (3,3), padding=\"same\")(inputs)\n",
    "    shared_map = KL.Activation(\"linear\")(shared_map)\n",
    "    rpn_class = KL.Conv2D(2*k, (1,1))(shared_map)\n",
    "    rpn_class = KL.Lambda(lambda x: tf.reshape(x, [tf.shape(x)[0], -1, 2]))(rpn_class)\n",
    "    rpn_class = KL.Activation(\"linear\")(rpn_class)\n",
    "    rpn_prob = KL.Activation(\"softmax\")(rpn_class)  # 分类的得分\n",
    "    \n",
    "    y = KL.Conv2D(4*k, (1,1))(shared_map)\n",
    "    y = KL.Activation(\"linear\")(y)\n",
    "    rpn_bbox = KL.Lambda(lambda x: tf.reshape(x, [tf.shape(x)[0], -1, 4]))(y)\n",
    "    \n",
    "    return rpn_class, rpn_prob, rpn_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_1 (BatchNorm)        (None, 224, 224, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 64) 0           batch_norm_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 112, 112, 64) 4160        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_2 (BatchNorm)        (None, 112, 112, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 112, 112, 64) 0           batch_norm_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 112, 112, 64) 36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_3 (BatchNorm)        (None, 112, 112, 64) 256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 112, 112, 64) 0           batch_norm_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 112, 112, 256 16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 112, 112, 256 16640       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_4 (BatchNorm)        (None, 112, 112, 256 1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_5 (BatchNorm)        (None, 112, 112, 256 1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 112, 112, 256 0           batch_norm_4[0][0]               \n",
      "                                                                 batch_norm_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 112, 112, 256 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 112, 112, 64) 16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_6 (BatchNorm)        (None, 112, 112, 64) 256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 112, 112, 64) 0           batch_norm_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 112, 112, 64) 36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_7 (BatchNorm)        (None, 112, 112, 64) 256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 112, 112, 64) 0           batch_norm_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 112, 112, 256 16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_8 (BatchNorm)        (None, 112, 112, 256 1024        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 112, 112, 256 0           batch_norm_8[0][0]               \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 112, 112, 256 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 112, 112, 64) 16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_9 (BatchNorm)        (None, 112, 112, 64) 256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 112, 112, 64) 0           batch_norm_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 112, 112, 64) 36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_10 (BatchNorm)       (None, 112, 112, 64) 256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 112, 112, 64) 0           batch_norm_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 112, 112, 256 16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_11 (BatchNorm)       (None, 112, 112, 256 1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 112, 112, 256 0           batch_norm_11[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 112, 112, 256 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 112, 112, 64) 16448       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_12 (BatchNorm)       (None, 112, 112, 64) 256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 112, 112, 64) 0           batch_norm_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 112, 112, 64) 36928       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_13 (BatchNorm)       (None, 112, 112, 64) 256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 112, 112, 64) 0           batch_norm_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 112, 112, 256 16640       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_14 (BatchNorm)       (None, 112, 112, 256 1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 112, 112, 256 0           batch_norm_14[0][0]              \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 112, 112, 256 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 56, 56, 128)  32896       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_15 (BatchNorm)       (None, 56, 56, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 56, 56, 128)  0           batch_norm_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 56, 56, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_16 (BatchNorm)       (None, 56, 56, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 56, 56, 128)  0           batch_norm_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 56, 56, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 56, 56, 512)  131584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_17 (BatchNorm)       (None, 56, 56, 512)  2048        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_18 (BatchNorm)       (None, 56, 56, 512)  2048        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 56, 56, 512)  0           batch_norm_17[0][0]              \n",
      "                                                                 batch_norm_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 56, 56, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 56, 56, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_19 (BatchNorm)       (None, 56, 56, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 56, 56, 128)  0           batch_norm_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 56, 56, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_20 (BatchNorm)       (None, 56, 56, 128)  512         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 56, 56, 128)  0           batch_norm_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 56, 56, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_21 (BatchNorm)       (None, 56, 56, 512)  2048        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 56, 56, 512)  0           batch_norm_21[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 56, 56, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 56, 56, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_22 (BatchNorm)       (None, 56, 56, 128)  512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 56, 56, 128)  0           batch_norm_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 56, 56, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_23 (BatchNorm)       (None, 56, 56, 128)  512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 56, 56, 128)  0           batch_norm_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 56, 56, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_24 (BatchNorm)       (None, 56, 56, 512)  2048        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 56, 56, 512)  0           batch_norm_24[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 56, 56, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 56, 56, 128)  65664       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_25 (BatchNorm)       (None, 56, 56, 128)  512         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 56, 56, 128)  0           batch_norm_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 56, 56, 128)  147584      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_26 (BatchNorm)       (None, 56, 56, 128)  512         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 56, 56, 128)  0           batch_norm_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 56, 56, 512)  66048       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_27 (BatchNorm)       (None, 56, 56, 512)  2048        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 56, 56, 512)  0           batch_norm_27[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 56, 56, 512)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 28, 28, 256)  131328      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_28 (BatchNorm)       (None, 28, 28, 256)  1024        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 28, 28, 256)  0           batch_norm_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 28, 28, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_29 (BatchNorm)       (None, 28, 28, 256)  1024        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 28, 28, 256)  0           batch_norm_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 28, 28, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 28, 28, 1024) 525312      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_30 (BatchNorm)       (None, 28, 28, 1024) 4096        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_31 (BatchNorm)       (None, 28, 28, 1024) 4096        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 28, 28, 1024) 0           batch_norm_30[0][0]              \n",
      "                                                                 batch_norm_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 28, 28, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 28, 28, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_32 (BatchNorm)       (None, 28, 28, 256)  1024        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 28, 28, 256)  0           batch_norm_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 28, 28, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_33 (BatchNorm)       (None, 28, 28, 256)  1024        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 28, 28, 256)  0           batch_norm_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 28, 28, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_34 (BatchNorm)       (None, 28, 28, 1024) 4096        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 28, 28, 1024) 0           batch_norm_34[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 28, 28, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 28, 28, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_35 (BatchNorm)       (None, 28, 28, 256)  1024        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 28, 28, 256)  0           batch_norm_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 28, 28, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_36 (BatchNorm)       (None, 28, 28, 256)  1024        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 28, 28, 256)  0           batch_norm_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 28, 28, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_37 (BatchNorm)       (None, 28, 28, 1024) 4096        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 28, 28, 1024) 0           batch_norm_37[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 28, 28, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 28, 28, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_38 (BatchNorm)       (None, 28, 28, 256)  1024        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 28, 28, 256)  0           batch_norm_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 28, 28, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_39 (BatchNorm)       (None, 28, 28, 256)  1024        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 28, 28, 256)  0           batch_norm_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 28, 28, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_40 (BatchNorm)       (None, 28, 28, 1024) 4096        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 28, 28, 1024) 0           batch_norm_40[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 28, 28, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 28, 28, 256)  2359552     activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 28, 28, 256)  0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 28, 28, 18)   4626        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None, 2)      0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 28, 28, 36)   9252        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, 2)      0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 28, 28, 36)   0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, 2)      0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, None, 4)      0           activation_41[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 8,782,902\n",
      "Trainable params: 8,757,686\n",
      "Non-trainable params: 25,216\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = KL.Input((224, 224, 3))  # change\n",
    "fp = resNet_featureExtractor(x)\n",
    "rpn_class, rpn_prob, rpn_bbox = rpn_net(fp, 9)\n",
    "model = Model([x], [rpn_class, rpn_prob, rpn_bbox])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算分类的loss\n",
    "def rpn_class_loss(rpn_match, rpn_class_logits):\n",
    "    ## rpn_match(None, 576, 1)\n",
    "    ## rpn_class_logits(None, 576, 2)\n",
    "    rpn_match = tf.squeeze(rpn_match, -1)   # 把最后1给压缩掉，变成1维\n",
    "    indices = tf.where(K.not_equal(rpn_match, 0))     # 取label不等于0的（也就是取IOU为1和-1的）\n",
    "    anchor_class = K.cast(K.equal(rpn_match, 1), tf.int32)  # 转换成int型\n",
    "    rpn_class_logits = tf.gather_nd(rpn_class_logits, indices)  # prediction\n",
    "    anchor_class = tf.gather_nd(anchor_class, indices)   # target\n",
    "    loss = K.sparse_categorical_crossentropy(target=anchor_class,\n",
    "                output=rpn_class_logits, from_logits=True)\n",
    "    # 过滤异常loss\n",
    "    loss = K.switch(tf.size(loss) > 0, K.mean(loss), tf.constant(0.0))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "# 计算框回归的loss\n",
    "def batch_back(x, counts, num_rows):\n",
    "    outputs = []\n",
    "    for i in range(num_rows):\n",
    "        outputs.append(x[i, :counts[i]])\n",
    "    return tf.concat(outputs, axis=0)\n",
    "def rpn_bbox_loss(target_bbox, rpn_match, rpn_bbox):\n",
    "    rpn_match = tf.squeeze(rpn_match, -1)   # 把最后1给压缩掉，变成1维\n",
    "    indices = tf.where(K.equal(rpn_match, 1))   # 取label等于1的\n",
    "    rpn_bbox = tf.gather_nd(rpn_bbox, indices)\n",
    "    batch_counts = K.sum(K.cast(K.equal(rpn_match, 1), tf.int32), axis=1) # 一维数据求和\n",
    "    target_bbox = batch_back(target_bbox, batch_counts, batch_size)\n",
    "    diff = K.abs(target_bbox - rpn_bbox)\n",
    "    less_than_one = K.cast(K.less(diff, 1.0), \"float32\")  # 是不是小于1的部分\n",
    "    loss = less_than_one * 0.5 * diff**2 + (1-less_than_one) * (diff-0.5)\n",
    "    loss = K.switch(tf.size(loss) > 0, K.mean(loss), tf.constant(0.0))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = KL.Input(shape=[224,224,3], dtype=tf.float32)  # change\n",
    "input_bboxes = KL.Input(shape=[None,4], dtype=tf.float32)     # 真实bbox\n",
    "input_class_ids = KL.Input(shape=[None], dtype=tf.int32)\n",
    "input_rpn_match = KL.Input(shape=[None,1], dtype=tf.int32)\n",
    "input_rpn_bbox = KL.Input(shape=[None,4], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-d074bbe2e135>:6: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "feature_map = resNet_featureExtractor(input_image)\n",
    "rpn_class, rpn_prob, rpn_bbox = rpn_net(feature_map, 9) # 每个9有个anchor\n",
    "loss_rpn_match = KL.Lambda(lambda x: rpn_class_loss(*x), name=\"loss_rpn_match\")(\n",
    "    [input_rpn_match, rpn_class]\n",
    ")\n",
    "loss_rpn_bbox = KL.Lambda(lambda x:rpn_bbox_loss(*x), name=\"loss_rpn_bbox\")(\n",
    "    [input_rpn_bbox, input_rpn_match, rpn_bbox]\n",
    ")\n",
    "model = Model(\n",
    "    [input_image, input_bboxes, input_class_ids, input_rpn_match, input_rpn_bbox],\n",
    "    [rpn_class, rpn_prob, rpn_bbox, loss_rpn_match, loss_rpn_bbox]\n",
    ")\n",
    "from keras.utils.vis_utils import plot_model\n",
    "# plot_model(model, to_file=\"model_rpn.png\", show_shapes=True)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "loss_lay1 = model.get_layer(\"loss_rpn_match\").output\n",
    "loss_lay2 = model.get_layer(\"loss_rpn_bbox\").output\n",
    "\n",
    "model.add_loss(tf.reduce_mean(loss_lay1))\n",
    "model.add_loss(tf.reduce_mean(loss_lay2))\n",
    "\n",
    "model.compile(loss=[None]*len(model.output), optimizer=keras.optimizers.SGD(lr=0.00005, momentum=0.9))\n",
    "\n",
    "model.metrics_names.append(\"loss_rpn_match\")\n",
    "# model.metrics_tensors.append(tf.reduce_mean(loss_lay1, keep_dims=True))\n",
    "model.metrics_names.append(\"loss_rpn_bbox\")\n",
    "# model.metrics_tensors.append(tf.reduce_mean(loss_lay2, keep_dims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import shapeData as dataSet\n",
    "from config import Config\n",
    "\n",
    "config = Config()\n",
    "dataset = dataSet([224, 224], config=config)  # change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import shapeData as dataSet\n",
    "# from config import Config\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# config = Config()\n",
    "# dataset = dataSet([64, 64], config=config)\n",
    "# for i in range(1):\n",
    "#     image, bbox, class_id, rpn_match, rpn_bbox, _ = data = dataset.load_data()\n",
    "#     plt.imshow(image)\n",
    "#     print(image)\n",
    "#     print(bbox)\n",
    "#     print(class_id)\n",
    "#     print(rpn_match)\n",
    "#     print(rpn_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_Gen(dataset, num_batch, batch_size, config):\n",
    "    for _ in range(num_batch):\n",
    "        images = []\n",
    "        bboxes = []\n",
    "        class_ids = []\n",
    "        rpn_matchs = []\n",
    "        rpn_bboxes = []\n",
    "        for i in range(batch_size):\n",
    "            image, bbox, class_id, rpn_match, rpn_bbox, _ = data = dataset.load_data()\n",
    "            pad_num = config.max_gt_obj - bbox.shape[0]\n",
    "            pad_box = np.zeros((pad_num, 4))\n",
    "            pad_ids = np.zeros((pad_num, 1))\n",
    "            bbox = np.concatenate([bbox, pad_box], axis=0)\n",
    "            class_id = np.concatenate([class_id, pad_ids], axis=0)\n",
    "        \n",
    "            images.append(image)\n",
    "            bboxes.append(bbox)\n",
    "            class_ids.append(class_id)\n",
    "            rpn_matchs.append(rpn_match)\n",
    "            rpn_bboxes.append(rpn_bbox)\n",
    "        images = np.concatenate(images, 0).reshape(batch_size, config.image_size[0],config.image_size[1] , 3)\n",
    "        bboxes = np.concatenate(bboxes, 0).reshape(batch_size, -1 , 4)\n",
    "        class_ids = np.concatenate(class_ids, 0).reshape(batch_size, -1 )\n",
    "        rpn_matchs = np.concatenate(rpn_matchs, 0).reshape(batch_size, -1 , 1)\n",
    "        rpn_bboxes = np.concatenate(rpn_bboxes, 0).reshape(batch_size, -1 , 4)\n",
    "        \n",
    "        yield [images, bboxes, class_ids, rpn_matchs, rpn_bboxes],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 35000          # 总数据\n",
    "steps_per_epoch = 5    # 步长\n",
    "\n",
    "dataGen = data_Gen(dataset, int(total / steps_per_epoch / batch_size), batch_size, config) # 35000个数据，batch_size=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "5/5 [==============================] - 16s 3s/step - loss: 3.8524\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 16s 3s/step - loss: 3.2739\n"
     ]
    }
   ],
   "source": [
    "his = model.fit_generator(dataGen, steps_per_epoch=steps_per_epoch, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_material_224_120.h5\")\n",
    "# model.load_weights(\"model_material1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anchor_refinement(boxes, deltas):\n",
    "    boxes = tf.cast(boxes, tf.float32)\n",
    "    h = boxes[:, 2] - boxes[:, 0]\n",
    "    w = boxes[:, 3] - boxes[:, 1]\n",
    "    center_y = boxes[:, 0] + h / 2\n",
    "    center_x = boxes[:, 1] + w / 2\n",
    "\n",
    "    center_y += deltas[:, 0] * h\n",
    "    center_x += deltas[:, 1] * w\n",
    "    h *= tf.exp(deltas[:, 2])\n",
    "    w *= tf.exp(deltas[:, 3])\n",
    "    \n",
    "    y1 = center_y - h / 2\n",
    "    x1 = center_x - w / 2\n",
    "    y2 = center_y + h / 2\n",
    "    x2 = center_x + w / 2\n",
    "    boxes = tf.stack([y1, x1, y2, x2], axis=1)\n",
    "    return boxes\n",
    "    \n",
    "def boxes_clip(boxes, window):\n",
    "    wy1, wx1, wy2, wx2 = tf.split(window, 4)\n",
    "    y1, x1, y2, x2 = tf.split(boxes, 4, axis=1)\n",
    "    y1 = tf.maximum(tf.minimum(y1, wy2), wy1)\n",
    "    x1 = tf.maximum(tf.minimum(x1, wx2), wx1)\n",
    "    y2 = tf.maximum(tf.minimum(y2, wy2), wy1)\n",
    "    x2 = tf.maximum(tf.minimum(x2, wx2), wx1)\n",
    "    cliped = tf.concat([y1, x1, y2, x2], axis=1)\n",
    "    cliped.set_shape((cliped.shape[0], 4))\n",
    "    return cliped\n",
    "    \n",
    "def batch_slice(inputs, graph_fn, batch_size):\n",
    "    if not isinstance(inputs, list):\n",
    "        inputs = [inputs]\n",
    "    output = []\n",
    "    for i in range(batch_size):\n",
    "        inputs_slice = [x[i] for x in inputs]\n",
    "        output_slice = graph_fn(*inputs_slice)\n",
    "        if not isinstance(output_slice, (list, tuple)):\n",
    "            output_slice = [output_slice]\n",
    "        output.append(output_slice)\n",
    "    output = list(zip(*output))\n",
    "    result = [tf.stack(o, axis=0) for o in output]\n",
    "    if len(result)==1:\n",
    "        result = result[0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.engine as KE\n",
    "\n",
    "class proposal(KE.Layer):\n",
    "    def __init__(self, proposal_count, nms_thresh, anchors, batch_size, config=None, **kwargs):\n",
    "        super(proposal, self).__init__(**kwargs)\n",
    "        self.proposal_count = proposal_count\n",
    "        self.anchors = anchors\n",
    "        self.nms_thresh = nms_thresh\n",
    "        self.batch_size = batch_size\n",
    "        self.config = config\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        probs = inputs[0][:, :, 1]\n",
    "        deltas = inputs[1]\n",
    "        deltas = deltas * np.reshape(self.config.RPN_BBOX_STD_DEV, (1, 1, 4))\n",
    "        prenms_num = min(100, self.anchors.shape[0])\n",
    "        idxs = tf.nn.top_k(probs, prenms_num).indices\n",
    "        \n",
    "        probs = batch_slice([probs, idxs], lambda x,y:tf.gather(x, y), self.batch_size)\n",
    "        deltas = batch_slice([deltas, idxs], lambda x,y:tf.gather(x, y), self.batch_size)\n",
    "        anchors = batch_slice([idxs], lambda x:tf.gather(self.anchors,x), self.batch_size)\n",
    "        refined_boxes = batch_slice([anchors, deltas], lambda x,y:anchor_refinement(x,y), self.batch_size)\n",
    "        H,W = self.config.image_size[:2]\n",
    "        windows = np.array([0,0,H,W]).astype(np.float32)\n",
    "        cliped_boxes = batch_slice([refined_boxes], lambda x:boxes_clip(x, windows), self.batch_size)\n",
    "        normalized_boxes = cliped_boxes / np.array([H,W,H,W])\n",
    "        def nms(normalized_boxes, scores):\n",
    "            idxs_ = tf.image.non_max_suppression(normalized_boxes, scores, self.proposal_count, self.nms_thresh)\n",
    "            box = tf.gather(normalized_boxes, idxs_)\n",
    "            pad_num = tf.maximum(self.proposal_count - tf.shape(normalized_boxes)[0],0)\n",
    "            box = tf.pad(box, [(0,pad_num),(0,0)])\n",
    "            return box\n",
    "        proposal_ = batch_slice([normalized_boxes, probs], nms, self.batch_size)\n",
    "        return proposal_\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.proposal_count, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = next(dataGen)[0]\n",
    "images = test_data[0]\n",
    "bboxes = test_data[1]\n",
    "class_ids = test_data[2]\n",
    "rpn_matchs = test_data[3]\n",
    "rpn_bboxes = test_data[4]\n",
    "\n",
    "rpn_class, rpn_prob, rpn_bbox, _, _ = \\\n",
    "                model.predict([images, bboxes, class_ids, rpn_matchs, rpn_bboxes])\n",
    "# 转tensor\n",
    "rpn_class = tf.convert_to_tensor(rpn_class)\n",
    "rpn_prob = tf.convert_to_tensor(rpn_prob)\n",
    "rpn_bbox = tf.convert_to_tensor(rpn_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "# change\n",
    "anchors = utils.anchor_gen([28,28], ratios=config.ratios, scales=config.scales, rpn_stride=config.rpn_stride,\n",
    "                           anchor_stride = config.anchor_stride)\n",
    "proposals = proposal(proposal_count=16, nms_thresh=0.7, anchors=anchors, batch_size=batch_size, config=config)([rpn_prob, rpn_bbox])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "proposals_ = sess.run(proposals) * 224 # change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "ix = random.sample(range(batch_size), 1)[0]\n",
    "proposal_ = proposals_[ix]\n",
    "img = images[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 85.92717  224.       221.6045   224.      ]\n",
      " [224.       224.       224.       224.      ]\n",
      " [ 27.854458 117.285645  29.143772 166.8009  ]\n",
      " [148.0758   135.20747  150.7731   157.933   ]\n",
      " [224.        22.19561  224.        35.948975]\n",
      " [ 19.481194 181.1289    60.01893  199.9195  ]\n",
      " [224.       158.6675   224.       166.05049 ]\n",
      " [224.       214.11655  224.       224.      ]\n",
      " [ 94.66727  224.       211.60025  224.      ]\n",
      " [224.       224.       224.       224.      ]\n",
      " [224.       110.78549  224.       160.28308 ]\n",
      " [224.       224.       224.       224.      ]\n",
      " [224.       224.       224.       224.      ]\n",
      " [224.       189.5421   224.       224.      ]\n",
      " [224.        49.53921  224.       117.70719 ]\n",
      " [224.         0.       224.        47.705215]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(img)\n",
    "axs = plt.gca()\n",
    "print(proposal_)\n",
    "for i in range(len(proposal_)):\n",
    "    box = proposal_[i]\n",
    "    rec = patches.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1], facecolor='none', edgecolor='b')\n",
    "    axs.add_patch(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
