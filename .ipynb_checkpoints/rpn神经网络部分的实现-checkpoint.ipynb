{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.layers as KL\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(KL.BatchNormalization):\n",
    "    def call(self, inputs, training=None):\n",
    "        return super(self.__class__, self).call(inputs, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet网络 的building_block\n",
    "# filter：卷积核的通道数\n",
    "# block：block的标识\n",
    "def building_block(filters, block):\n",
    "    if block != 0:\n",
    "        stride = 1\n",
    "    else:\n",
    "        stride = 2\n",
    "    \n",
    "    def f(x):\n",
    "        y = KL.Conv2D(filters, (1,1), strides=stride)(x)  # 卷积核1×1\n",
    "        y = BatchNorm(axis=3)(y)\n",
    "        y = KL.Activation(\"relu\")(y)\n",
    "        \n",
    "        y = KL.Conv2D(filters, (3,3), padding=\"same\")(y)  # 卷积核1×1\n",
    "        y = BatchNorm(axis=3)(y)\n",
    "        y = KL.Activation(\"relu\")(y)\n",
    "        \n",
    "        y = KL.Conv2D(4 * filters, (1,1))(y)\n",
    "        y = BatchNorm(axis=3)(y)\n",
    "        \n",
    "        if block == 0:\n",
    "            shorcut = KL.Conv2D(4*filters, (1,1), strides=stride)(x)\n",
    "            shorcut = BatchNorm(axis=3)(shorcut)\n",
    "        else:\n",
    "            shorcut = x\n",
    "        y = KL.Add()([y, shorcut])\n",
    "        y = KL.Activation(\"relu\")(y)\n",
    "        return y\n",
    "    return f\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet网络\n",
    "def resNet_featureExtractor(inputs):\n",
    "    x = KL.Conv2D(64, (3,3), padding=\"same\")(inputs)\n",
    "    x = BatchNorm(axis=3)(x)\n",
    "    x = KL.Activation(\"relu\")(x)\n",
    "    \n",
    "    filters = 64   # 第一个卷积核的通道数\n",
    "    blocks = [4, 4, 4]    # buildblock的数量  change\n",
    "    \n",
    "    for i, block_num in enumerate(blocks):\n",
    "        for block_id in range(block_num):\n",
    "            x = building_block(filters, block_id)(x)\n",
    "        filters = filters * 2\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rpn_net(inputs, k):\n",
    "    shared_map = KL.Conv2D(256, (3,3), padding=\"same\")(inputs)\n",
    "    shared_map = KL.Activation(\"linear\")(shared_map)\n",
    "    rpn_class = KL.Conv2D(2*k, (1,1))(shared_map)\n",
    "    rpn_class = KL.Lambda(lambda x: tf.reshape(x, [tf.shape(x)[0], -1, 2]))(rpn_class)\n",
    "    rpn_class = KL.Activation(\"linear\")(rpn_class)\n",
    "    rpn_prob = KL.Activation(\"softmax\")(rpn_class)  # 分类的得分\n",
    "    \n",
    "    y = KL.Conv2D(4*k, (1,1))(shared_map)\n",
    "    y = KL.Activation(\"linear\")(y)\n",
    "    rpn_bbox = KL.Lambda(lambda x: tf.reshape(x, [tf.shape(x)[0], -1, 4]))(y)\n",
    "    \n",
    "    return rpn_class, rpn_prob, rpn_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_1 (BatchNorm)        (None, 224, 224, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 64) 0           batch_norm_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 112, 112, 64) 4160        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_2 (BatchNorm)        (None, 112, 112, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 112, 112, 64) 0           batch_norm_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 112, 112, 64) 36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_3 (BatchNorm)        (None, 112, 112, 64) 256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 112, 112, 64) 0           batch_norm_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 112, 112, 256 16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 112, 112, 256 16640       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_4 (BatchNorm)        (None, 112, 112, 256 1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_5 (BatchNorm)        (None, 112, 112, 256 1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 112, 112, 256 0           batch_norm_4[0][0]               \n",
      "                                                                 batch_norm_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 112, 112, 256 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 112, 112, 64) 16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_6 (BatchNorm)        (None, 112, 112, 64) 256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 112, 112, 64) 0           batch_norm_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 112, 112, 64) 36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_7 (BatchNorm)        (None, 112, 112, 64) 256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 112, 112, 64) 0           batch_norm_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 112, 112, 256 16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_8 (BatchNorm)        (None, 112, 112, 256 1024        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 112, 112, 256 0           batch_norm_8[0][0]               \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 112, 112, 256 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 112, 112, 64) 16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_9 (BatchNorm)        (None, 112, 112, 64) 256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 112, 112, 64) 0           batch_norm_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 112, 112, 64) 36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_10 (BatchNorm)       (None, 112, 112, 64) 256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 112, 112, 64) 0           batch_norm_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 112, 112, 256 16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_11 (BatchNorm)       (None, 112, 112, 256 1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 112, 112, 256 0           batch_norm_11[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 112, 112, 256 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 112, 112, 64) 16448       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_12 (BatchNorm)       (None, 112, 112, 64) 256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 112, 112, 64) 0           batch_norm_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 112, 112, 64) 36928       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_13 (BatchNorm)       (None, 112, 112, 64) 256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 112, 112, 64) 0           batch_norm_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 112, 112, 256 16640       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_14 (BatchNorm)       (None, 112, 112, 256 1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 112, 112, 256 0           batch_norm_14[0][0]              \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 112, 112, 256 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 56, 56, 128)  32896       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_15 (BatchNorm)       (None, 56, 56, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 56, 56, 128)  0           batch_norm_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 56, 56, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_16 (BatchNorm)       (None, 56, 56, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 56, 56, 128)  0           batch_norm_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 56, 56, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 56, 56, 512)  131584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_17 (BatchNorm)       (None, 56, 56, 512)  2048        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_18 (BatchNorm)       (None, 56, 56, 512)  2048        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 56, 56, 512)  0           batch_norm_17[0][0]              \n",
      "                                                                 batch_norm_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 56, 56, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 56, 56, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_19 (BatchNorm)       (None, 56, 56, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 56, 56, 128)  0           batch_norm_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 56, 56, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_20 (BatchNorm)       (None, 56, 56, 128)  512         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 56, 56, 128)  0           batch_norm_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 56, 56, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_21 (BatchNorm)       (None, 56, 56, 512)  2048        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 56, 56, 512)  0           batch_norm_21[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 56, 56, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 56, 56, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_22 (BatchNorm)       (None, 56, 56, 128)  512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 56, 56, 128)  0           batch_norm_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 56, 56, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_23 (BatchNorm)       (None, 56, 56, 128)  512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 56, 56, 128)  0           batch_norm_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 56, 56, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_24 (BatchNorm)       (None, 56, 56, 512)  2048        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 56, 56, 512)  0           batch_norm_24[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 56, 56, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 56, 56, 128)  65664       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_25 (BatchNorm)       (None, 56, 56, 128)  512         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 56, 56, 128)  0           batch_norm_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 56, 56, 128)  147584      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_26 (BatchNorm)       (None, 56, 56, 128)  512         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 56, 56, 128)  0           batch_norm_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 56, 56, 512)  66048       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_27 (BatchNorm)       (None, 56, 56, 512)  2048        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 56, 56, 512)  0           batch_norm_27[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 56, 56, 512)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 28, 28, 256)  131328      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_28 (BatchNorm)       (None, 28, 28, 256)  1024        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 28, 28, 256)  0           batch_norm_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 28, 28, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_29 (BatchNorm)       (None, 28, 28, 256)  1024        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 28, 28, 256)  0           batch_norm_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 28, 28, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 28, 28, 1024) 525312      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_30 (BatchNorm)       (None, 28, 28, 1024) 4096        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_31 (BatchNorm)       (None, 28, 28, 1024) 4096        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 28, 28, 1024) 0           batch_norm_30[0][0]              \n",
      "                                                                 batch_norm_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 28, 28, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 28, 28, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_32 (BatchNorm)       (None, 28, 28, 256)  1024        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 28, 28, 256)  0           batch_norm_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 28, 28, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_33 (BatchNorm)       (None, 28, 28, 256)  1024        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 28, 28, 256)  0           batch_norm_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 28, 28, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_34 (BatchNorm)       (None, 28, 28, 1024) 4096        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 28, 28, 1024) 0           batch_norm_34[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 28, 28, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 28, 28, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_35 (BatchNorm)       (None, 28, 28, 256)  1024        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 28, 28, 256)  0           batch_norm_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 28, 28, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_36 (BatchNorm)       (None, 28, 28, 256)  1024        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 28, 28, 256)  0           batch_norm_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 28, 28, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_37 (BatchNorm)       (None, 28, 28, 1024) 4096        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 28, 28, 1024) 0           batch_norm_37[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 28, 28, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 28, 28, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_38 (BatchNorm)       (None, 28, 28, 256)  1024        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 28, 28, 256)  0           batch_norm_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 28, 28, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_39 (BatchNorm)       (None, 28, 28, 256)  1024        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 28, 28, 256)  0           batch_norm_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 28, 28, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_40 (BatchNorm)       (None, 28, 28, 1024) 4096        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 28, 28, 1024) 0           batch_norm_40[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 28, 28, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 28, 28, 256)  2359552     activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 28, 28, 256)  0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 28, 28, 18)   4626        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None, 2)      0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 28, 28, 36)   9252        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, 2)      0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 28, 28, 36)   0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, 2)      0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, None, 4)      0           activation_41[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 8,782,902\n",
      "Trainable params: 8,757,686\n",
      "Non-trainable params: 25,216\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = KL.Input((224, 224, 3))  # change\n",
    "fp = resNet_featureExtractor(x)\n",
    "rpn_class, rpn_prob, rpn_bbox = rpn_net(fp, 9)\n",
    "model = Model([x], [rpn_class, rpn_prob, rpn_bbox])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算分类的loss\n",
    "def rpn_class_loss(rpn_match, rpn_class_logits):\n",
    "    ## rpn_match(None, 576, 1)\n",
    "    ## rpn_class_logits(None, 576, 2)\n",
    "    rpn_match = tf.squeeze(rpn_match, -1)   # 把最后1给压缩掉，变成1维\n",
    "    indices = tf.where(K.not_equal(rpn_match, 0))     # 取label不等于0的（也就是取IOU为1和-1的）\n",
    "    anchor_class = K.cast(K.equal(rpn_match, 1), tf.int32)  # 转换成int型\n",
    "    rpn_class_logits = tf.gather_nd(rpn_class_logits, indices)  # prediction\n",
    "    anchor_class = tf.gather_nd(anchor_class, indices)   # target\n",
    "    loss = K.sparse_categorical_crossentropy(target=anchor_class,\n",
    "                output=rpn_class_logits, from_logits=True)\n",
    "    # 过滤异常loss\n",
    "    loss = K.switch(tf.size(loss) > 0, K.mean(loss), tf.constant(0.0))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "# 计算框回归的loss\n",
    "def batch_back(x, counts, num_rows):\n",
    "    outputs = []\n",
    "    for i in range(num_rows):\n",
    "        outputs.append(x[i, :counts[i]])\n",
    "    return tf.concat(outputs, axis=0)\n",
    "def rpn_bbox_loss(target_bbox, rpn_match, rpn_bbox):\n",
    "    rpn_match = tf.squeeze(rpn_match, -1)   # 把最后1给压缩掉，变成1维\n",
    "    indices = tf.where(K.equal(rpn_match, 1))   # 取label等于1的\n",
    "    rpn_bbox = tf.gather_nd(rpn_bbox, indices)\n",
    "    batch_counts = K.sum(K.cast(K.equal(rpn_match, 1), tf.int32), axis=1) # 一维数据求和\n",
    "    target_bbox = batch_back(target_bbox, batch_counts, batch_size)\n",
    "    diff = K.abs(target_bbox - rpn_bbox)\n",
    "    less_than_one = K.cast(K.less(diff, 1.0), \"float32\")  # 是不是小于1的部分\n",
    "    loss = less_than_one * 0.5 * diff**2 + (1-less_than_one) * (diff-0.5)\n",
    "    loss = K.switch(tf.size(loss) > 0, K.mean(loss), tf.constant(0.0))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = KL.Input(shape=[224,224,3], dtype=tf.float32)  # change\n",
    "input_bboxes = KL.Input(shape=[None,4], dtype=tf.float32)     # 真实bbox\n",
    "input_class_ids = KL.Input(shape=[None], dtype=tf.int32)\n",
    "input_rpn_match = KL.Input(shape=[None,1], dtype=tf.int32)\n",
    "input_rpn_bbox = KL.Input(shape=[None,4], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-d074bbe2e135>:6: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "feature_map = resNet_featureExtractor(input_image)\n",
    "rpn_class, rpn_prob, rpn_bbox = rpn_net(feature_map, 9) # 每个9有个anchor\n",
    "loss_rpn_match = KL.Lambda(lambda x: rpn_class_loss(*x), name=\"loss_rpn_match\")(\n",
    "    [input_rpn_match, rpn_class]\n",
    ")\n",
    "loss_rpn_bbox = KL.Lambda(lambda x:rpn_bbox_loss(*x), name=\"loss_rpn_bbox\")(\n",
    "    [input_rpn_bbox, input_rpn_match, rpn_bbox]\n",
    ")\n",
    "model = Model(\n",
    "    [input_image, input_bboxes, input_class_ids, input_rpn_match, input_rpn_bbox],\n",
    "    [rpn_class, rpn_prob, rpn_bbox, loss_rpn_match, loss_rpn_bbox]\n",
    ")\n",
    "from keras.utils.vis_utils import plot_model\n",
    "# plot_model(model, to_file=\"model_rpn.png\", show_shapes=True)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "loss_lay1 = model.get_layer(\"loss_rpn_match\").output\n",
    "loss_lay2 = model.get_layer(\"loss_rpn_bbox\").output\n",
    "\n",
    "model.add_loss(tf.reduce_mean(loss_lay1))\n",
    "model.add_loss(tf.reduce_mean(loss_lay2))\n",
    "\n",
    "model.compile(loss=[None]*len(model.output), optimizer=keras.optimizers.SGD(lr=0.00005, momentum=0.9))\n",
    "\n",
    "model.metrics_names.append(\"loss_rpn_match\")\n",
    "# model.metrics_tensors.append(tf.reduce_mean(loss_lay1, keep_dims=True))\n",
    "model.metrics_names.append(\"loss_rpn_bbox\")\n",
    "# model.metrics_tensors.append(tf.reduce_mean(loss_lay2, keep_dims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import shapeData as dataSet\n",
    "from config import Config\n",
    "\n",
    "config = Config()\n",
    "dataset = dataSet([224, 224], config=config)  # change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import shapeData as dataSet\n",
    "# from config import Config\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# config = Config()\n",
    "# dataset = dataSet([64, 64], config=config)\n",
    "# for i in range(1):\n",
    "#     image, bbox, class_id, rpn_match, rpn_bbox, _ = data = dataset.load_data()\n",
    "#     plt.imshow(image)\n",
    "#     print(image)\n",
    "#     print(bbox)\n",
    "#     print(class_id)\n",
    "#     print(rpn_match)\n",
    "#     print(rpn_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_Gen(dataset, num_batch, batch_size, config):\n",
    "    for _ in range(num_batch):\n",
    "        images = []\n",
    "        bboxes = []\n",
    "        class_ids = []\n",
    "        rpn_matchs = []\n",
    "        rpn_bboxes = []\n",
    "        for i in range(batch_size):\n",
    "            image, bbox, class_id, rpn_match, rpn_bbox, _ = data = dataset.load_data()\n",
    "            pad_num = config.max_gt_obj - bbox.shape[0]\n",
    "            pad_box = np.zeros((pad_num, 4))\n",
    "            pad_ids = np.zeros((pad_num, 1))\n",
    "            bbox = np.concatenate([bbox, pad_box], axis=0)\n",
    "            class_id = np.concatenate([class_id, pad_ids], axis=0)\n",
    "        \n",
    "            images.append(image)\n",
    "            bboxes.append(bbox)\n",
    "            class_ids.append(class_id)\n",
    "            rpn_matchs.append(rpn_match)\n",
    "            rpn_bboxes.append(rpn_bbox)\n",
    "        images = np.concatenate(images, 0).reshape(batch_size, config.image_size[0],config.image_size[1] , 3)\n",
    "        bboxes = np.concatenate(bboxes, 0).reshape(batch_size, -1 , 4)\n",
    "        class_ids = np.concatenate(class_ids, 0).reshape(batch_size, -1 )\n",
    "        rpn_matchs = np.concatenate(rpn_matchs, 0).reshape(batch_size, -1 , 1)\n",
    "        rpn_bboxes = np.concatenate(rpn_bboxes, 0).reshape(batch_size, -1 , 4)\n",
    "        \n",
    "        yield [images, bboxes, class_ids, rpn_matchs, rpn_bboxes],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 35000          # 总数据\n",
    "steps_per_epoch = 5    # 步长\n",
    "\n",
    "dataGen = data_Gen(dataset, int(total / steps_per_epoch / batch_size), batch_size, config) # 35000个数据，batch_size=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2/2 [==============================] - 11s 6s/step - loss: 4.9671\n"
     ]
    }
   ],
   "source": [
    "his = model.fit_generator(dataGen, steps_per_epoch=steps_per_epoch, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_material_224_120.h5\")\n",
    "# model.load_weights(\"model_material1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anchor_refinement(boxes, deltas):\n",
    "    boxes = tf.cast(boxes, tf.float32)\n",
    "    h = boxes[:, 2] - boxes[:, 0]\n",
    "    w = boxes[:, 3] - boxes[:, 1]\n",
    "    center_y = boxes[:, 0] + h / 2\n",
    "    center_x = boxes[:, 1] + w / 2\n",
    "\n",
    "    center_y += deltas[:, 0] * h\n",
    "    center_x += deltas[:, 1] * w\n",
    "    h *= tf.exp(deltas[:, 2])\n",
    "    w *= tf.exp(deltas[:, 3])\n",
    "    \n",
    "    y1 = center_y - h / 2\n",
    "    x1 = center_x - w / 2\n",
    "    y2 = center_y + h / 2\n",
    "    x2 = center_x + w / 2\n",
    "    boxes = tf.stack([y1, x1, y2, x2], axis=1)\n",
    "    return boxes\n",
    "    \n",
    "def boxes_clip(boxes, window):\n",
    "    wy1, wx1, wy2, wx2 = tf.split(window, 4)\n",
    "    y1, x1, y2, x2 = tf.split(boxes, 4, axis=1)\n",
    "    y1 = tf.maximum(tf.minimum(y1, wy2), wy1)\n",
    "    x1 = tf.maximum(tf.minimum(x1, wx2), wx1)\n",
    "    y2 = tf.maximum(tf.minimum(y2, wy2), wy1)\n",
    "    x2 = tf.maximum(tf.minimum(x2, wx2), wx1)\n",
    "    cliped = tf.concat([y1, x1, y2, x2], axis=1)\n",
    "    cliped.set_shape((cliped.shape[0], 4))\n",
    "    return cliped\n",
    "    \n",
    "def batch_slice(inputs, graph_fn, batch_size):\n",
    "    if not isinstance(inputs, list):\n",
    "        inputs = [inputs]\n",
    "    output = []\n",
    "    for i in range(batch_size):\n",
    "        inputs_slice = [x[i] for x in inputs]\n",
    "        output_slice = graph_fn(*inputs_slice)\n",
    "        if not isinstance(output_slice, (list, tuple)):\n",
    "            output_slice = [output_slice]\n",
    "        output.append(output_slice)\n",
    "    output = list(zip(*output))\n",
    "    result = [tf.stack(o, axis=0) for o in output]\n",
    "    if len(result)==1:\n",
    "        result = result[0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.engine as KE\n",
    "\n",
    "class proposal(KE.Layer):\n",
    "    def __init__(self, proposal_count, nms_thresh, anchors, batch_size, config=None, **kwargs):\n",
    "        super(proposal, self).__init__(**kwargs)\n",
    "        self.proposal_count = proposal_count\n",
    "        self.anchors = anchors\n",
    "        self.nms_thresh = nms_thresh\n",
    "        self.batch_size = batch_size\n",
    "        self.config = config\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        probs = inputs[0][:, :, 1]\n",
    "        deltas = inputs[1]\n",
    "        deltas = deltas * np.reshape(self.config.RPN_BBOX_STD_DEV, (1, 1, 4))\n",
    "        prenms_num = min(100, self.anchors.shape[0])\n",
    "        idxs = tf.nn.top_k(probs, prenms_num).indices\n",
    "        \n",
    "        probs = batch_slice([probs, idxs], lambda x,y:tf.gather(x, y), self.batch_size)\n",
    "        deltas = batch_slice([deltas, idxs], lambda x,y:tf.gather(x, y), self.batch_size)\n",
    "        anchors = batch_slice([idxs], lambda x:tf.gather(self.anchors,x), self.batch_size)\n",
    "        refined_boxes = batch_slice([anchors, deltas], lambda x,y:anchor_refinement(x,y), self.batch_size)\n",
    "        H,W = self.config.image_size[:2]\n",
    "        windows = np.array([0,0,H,W]).astype(np.float32)\n",
    "        cliped_boxes = batch_slice([refined_boxes], lambda x:boxes_clip(x, windows), self.batch_size)\n",
    "        normalized_boxes = cliped_boxes / np.array([H,W,H,W])\n",
    "        def nms(normalized_boxes, scores):\n",
    "            idxs_ = tf.image.non_max_suppression(normalized_boxes, scores, self.proposal_count, self.nms_thresh)\n",
    "            box = tf.gather(normalized_boxes, idxs_)\n",
    "            pad_num = tf.maximum(self.proposal_count - tf.shape(normalized_boxes)[0],0)\n",
    "            box = tf.pad(box, [(0,pad_num),(0,0)])\n",
    "            return box\n",
    "        proposal_ = batch_slice([normalized_boxes, probs], nms, self.batch_size)\n",
    "        return proposal_\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.proposal_count, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = next(dataGen)[0]\n",
    "images = test_data[0]\n",
    "bboxes = test_data[1]\n",
    "class_ids = test_data[2]\n",
    "rpn_matchs = test_data[3]\n",
    "rpn_bboxes = test_data[4]\n",
    "\n",
    "rpn_class, rpn_prob, rpn_bbox, _, _ = \\\n",
    "                model.predict([images, bboxes, class_ids, rpn_matchs, rpn_bboxes])\n",
    "# 转tensor\n",
    "rpn_class = tf.convert_to_tensor(rpn_class)\n",
    "rpn_prob = tf.convert_to_tensor(rpn_prob)\n",
    "rpn_bbox = tf.convert_to_tensor(rpn_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "# change\n",
    "anchors = utils.anchor_gen([28,28], ratios=config.ratios, scales=config.scales, rpn_stride=config.rpn_stride,\n",
    "                           anchor_stride = config.anchor_stride)\n",
    "proposals = proposal(proposal_count=16, nms_thresh=0.7, anchors=anchors, batch_size=batch_size, config=config)([rpn_prob, rpn_bbox])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "proposals_ = sess.run(proposals) * 224 # change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "ix = random.sample(range(batch_size), 1)[0]\n",
    "proposal_ = proposals_[ix]\n",
    "img = images[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[224.       209.97137  224.       224.      ]\n",
      " [224.       224.       224.       224.      ]\n",
      " [224.        25.005512 224.       128.66266 ]\n",
      " [224.       137.00267  224.       224.      ]\n",
      " [224.         0.       224.        72.66614 ]\n",
      " [224.       224.       224.       224.      ]\n",
      " [224.        11.002644 224.       114.66614 ]\n",
      " [224.       109.00267  224.       212.66612 ]\n",
      " [224.         0.       224.        86.66614 ]\n",
      " [224.       224.       224.       224.      ]\n",
      " [224.       224.       224.       224.      ]\n",
      " [224.       123.00267  224.       224.      ]\n",
      " [224.       151.00267  224.       224.      ]\n",
      " [224.         0.       224.       100.66614 ]\n",
      " [224.       206.94199  224.       224.      ]\n",
      " [224.         0.       224.        58.666115]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAPh0lEQVR4nO3dbawc5XnG8f9V8yIVqDCxjZCxa4OcKKRqjXtEkSgoLU0CVhVDJVJbFbgpqkECCdRUqgGpRf2UpgEk1JYIhBVTEV5aQ/EHp8GyUFCkmnBMjMExBttx4GDLdkgFqERJbe5+mGfLcLyHs96ZOTPr5/pJq519dnb3Xs3Z6zwzu5pbEYGZ5evX2i7AzNrlEDDLnEPALHMOAbPMOQTMMucQMMtcYyEg6SpJuyXtkbS2qdcxs2rUxO8EJM0CXge+AEwALwKrIuLHtb+YmVXS1EzgEmBPROyLiF8BjwMrGnotM6vglIaedz7wVun2BPB7U608Z86cWLRoUUOlmBnAtm3bfhYRcyePNxUC6jP2sf0OSWuANQALFy5kfHy8oVLMDEDST/uNN7U7MAEsKN0+HzhQXiEiHoyIsYgYmzv3uHAysxnSVAi8CCyRtFjSacBKYGNDr2VmFTSyOxARRyXdCnwPmAWsi4idTbyWmVXT1DEBImITsKmp5zezevgXg2aZcwiYZc4hYJY5h4BZ5hwCZplzCJhlziFgljmHgFnmHAJmmXMImGXOIWCWOYeAWeYcAmaZcwiYZc4hYJa5oUNA0gJJz0naJWmnpNvS+N2S3pa0PV2W11eumdWtyklFjgJfi4iXJJ0FbJO0Od13X0R8s3p5Zta0oUMgIg4CB9Py+5J2UZxq3MxGSC3HBCQtAi4GXkhDt0raIWmdpNl1vIaZNaNyCEg6E9gA3B4R7wEPABcCSylmCvdM8bg1ksYljR85cqRqGWY2pEohIOlUigB4NCKeAoiIQxFxLCI+BB6iaEl2HPcdMOuGKt8OCHgY2BUR95bGzyutdi3w6vDlmVnTqnw7cBlwPfCKpO1p7E5glaSlFG3H9gM3VarQzBpV5duBH9C/56B7DZiNEP9i0CxzDgGzzDkEzDLnEDDLnEPALHMOAbPMOQTMMucQMMucQ8Ascw4Bs8w5BMwy5xAwy5xDwCxzDgGzzDkEzDLnEDDLXJUzCwEgaT/wPnAMOBoRY5LOAZ4AFlGcXegrEfHfVV/LzOpX10zgDyJiaUSMpdtrgS0RsQTYkm6bWQc1tTuwAlifltcD1zT0OmZWUR0hEMCzkrZJWpPGzk0dinqdiuZNfpD7Dph1Q+VjAsBlEXFA0jxgs6TXBnlQRDwIPAgwNjYWNdRhZkOoPBOIiAPp+jDwNEWzkUO9/gPp+nDV1zGzZlTtQHRG6kiMpDOAL1I0G9kIrE6rrQaeqfI6ZtacqrsD5wJPF82IOAX4TkT8p6QXgScl3Qi8CVxX8XXMrCGVQiAi9gG/02f8HeDKKs9tQ5IgfIjFBudfDJ5MpI9fmw3AIWCWOYfAyWLyf3/PBmxADgGzzDkETgZT/df3bMAG4BAYdf6gW0UOgZOdQ8Km4RAYZYN+wB0E9gkcAmaZcwiMqhP97+7ZgE3BITCK/IG2GjkEcuLwsD4cAqPGH2SrmUPALHMOgVFSxyzAMwmbZOjzCUj6DEVvgZ4LgL8Fzgb+EuidPfTOiNg0dIVW8IfXGjJ0CETEbmApgKRZwNsU5xj8KnBfRHyzlgqtfj7xiJXUtTtwJbA3In5a0/NZmWcB1qC6QmAl8Fjp9q2SdkhaJ2l2Ta9hdXKwWFI5BCSdBnwZ+Lc09ABwIcWuwkHgnike5+Yjg/CH1RpWx0zgauCliDgEEBGHIuJYRHwIPETRh+A4EfFgRIxFxNjcuXNrKOMk1HQAOGCMekJgFaVdgV7TkeRaij4E1lUOguxVOuW4pF8HvgDcVBr+hqSlFD0K90+6zwblD6fNkKp9Bz4APjVp7PpKFdnM81eGWfMvBrvIswCbQQ6BrmkrABw82XII2EccBFlyCHSJP4TWAoeAfZyDKDsOga7wh89a4hDogq4FQNfqsUY5BMwy5xBoW1f/63a1LqudQ8Cm5iDIgkOgTf6QWQc4BNoyKgEwKnXa0BwCbRi1D9ao1WsnxCFgljmHwEwb1f+qo1q3TWugEEgnDD0s6dXS2DmSNkt6I13PTuOSdL+kPelko8uaKn4kRYzuxU5Kg84Evg1cNWlsLbAlIpYAW9JtKM45uCRd1lCceNTMOmqgEIiI54GfTxpeAaxPy+uBa0rjj0RhK3D2pPMOmlmHVDkmcG5EHARI1/PS+HzgrdJ6E2nMzDqoiQOD/Y4gHbdD6b4DZt1QJQQO9ab56fpwGp8AFpTWOx84MPnB7jtg1g1VQmAjsDotrwaeKY3fkL4luBR4t7fbYGbdM9ApxyU9BnwemCNpAvg74OvAk5JuBN4ErkurbwKWA3uADyi6FJtZRw0UAhGxaoq7ruyzbgC3VCnKzGaOfzFoljmHgFnmHAJmmXMImGXOIWCWOYeAWeYcAmaZcwiYZc4hYJY5h4BZ5hwCZplzCJhlziFgljmHgFnmHAJmmXMImGVu2hCYovHIP0p6LTUXeVrS2Wl8kaRfSNqeLt9qsngzq26QmcC3Ob7xyGbgtyLit4HXgTtK9+2NiKXpcnM9ZZpZU6YNgX6NRyLi2Yg4mm5upTijsJmNoDqOCfwF8N3S7cWSfiTp+5Iun+pB7jtg1g2VQkDSXcBR4NE0dBBYGBEXA38FfEfSb/R7rPsOmHXD0CEgaTXwx8CfpTMMExG/jIh30vI2YC/w6ToKNbNmDBUCkq4C/gb4ckR8UBqfK2lWWr6AojPxvjoKNbNmTNt3YIrGI3cApwObJQFsTd8EXAH8vaSjwDHg5oiY3M3YzDpk2hCYovHIw1OsuwHYULUoM5s5/sWgWeYcAmaZcwiYZc4hYJY5h4BZ5hwCZplzCJhlziFgljmHgFnmHAJmmXMImGXOIWCWOYeAWeYcAmaZcwiYZW7YvgN3S3q71F9geem+OyTtkbRb0peaKtzM6jFs3wGA+0r9BTYBSLoIWAl8Lj3mX3qnGzOzbhqq78AnWAE8nk44+hNgD3BJhfrMrGFVjgncmtqQrZM0O43NB94qrTORxo7jvgNm3TBsCDwAXAgspeg1cE8aV591o98TuO+AWTcMFQIRcSgijkXEh8BDfDTlnwAWlFY9HzhQrUQza9KwfQfOK928Fuh9c7ARWCnpdEmLKfoO/LBaiWbWpGH7Dnxe0lKKqf5+4CaAiNgp6UngxxTtyW6JiGPNlG5mdVDqINaqsbGxGB8fb7sMs5OapG0RMTZ53L8YNMucQ8Ascw4Bs8w5BMwy5xAwy5xDwCxzDgGzzDkEzDLnEDDLnEPALHMOAbPMOQTMMucQMMucQ8Ascw4Bs8wN23fgiVLPgf2StqfxRZJ+UbrvW00Wb2bVTXtmIYq+A/8EPNIbiIg/7S1Lugd4t7T+3ohYWleBZtasaUMgIp6XtKjffZIEfAX4w3rLMrOZUvWYwOXAoYh4ozS2WNKPJH1f0uUVn9/MGjbI7sAnWQU8Vrp9EFgYEe9I+l3gPyR9LiLem/xASWuANQALFy6sWIaZDWvomYCkU4A/AZ7ojaX2Y++k5W3AXuDT/R7v5iNm3VBld+CPgNciYqI3IGlurwGppAso+g7sq1aimTVpkK8IHwP+C/iMpAlJN6a7VvLxXQGAK4Adkl4G/h24OSIGbWZqZi0Y5NuBVVOM/3mfsQ3AhuplmdlM8S8GzTLnEDDLnEPALHMOAbPMOQTMMucQMMucQ8Ascw4Bs8w5BMwy5xAwy5xDwCxzDgGzzDkEzDLnEDDLnEPALHODnFRkgaTnJO2StFPSbWn8HEmbJb2RrmencUm6X9IeSTskLWv6TZjZ8AaZCRwFvhYRnwUuBW6RdBGwFtgSEUuALek2wNUUpxVbQnEi0Qdqr9rMajNtCETEwYh4KS2/D+wC5gMrgPVptfXANWl5BfBIFLYCZ0s6r/bKzawWJ3RMIDUhuRh4ATg3Ig5CERTAvLTafOCt0sMm0piZddDAISDpTIrzB97er49AedU+Y9Hn+dZIGpc0fuTIkUHLMLOaDRQCkk6lCIBHI+KpNHyoN81P14fT+ASwoPTw84EDk5/TfQfMumGQbwcEPAzsioh7S3dtBFan5dXAM6XxG9K3BJcC7/Z2G8ysewZpQ3YZcD3wSq8FOXAn8HXgydSH4E3gunTfJmA5sAf4APhqrRWbWa0G6TvwA/rv5wNc2Wf9AG6pWJeZzRD/YtAscw4Bs8w5BMwy5xAwy5xDwCxzDgGzzDkEzDLnEDDLnEPALHMOAbPMOQTMMucQMMucQ8Ascw4Bs8w5BMwy5xAwy5xDwCxzDgGzzKk4G1jLRUhHgP8BftZ2LRXMYbTrh9F/D6NePzT7Hn4zIo47tXcnQgBA0nhEjLVdx7BGvX4Y/fcw6vVDO+/BuwNmmXMImGWuSyHwYNsFVDTq9cPov4dRrx9aeA+dOSZgZu3o0kzAzFrQeghIukrSbkl7JK1tu55BSdov6RVJ2yWNp7FzJG2W9Ea6nt12nWWS1kk6LOnV0ljfmlMvyfvTdtkhaVl7lf9/rf3qv1vS22k7bJe0vHTfHan+3ZK+1E7VH5G0QNJzknZJ2inptjTe7jaIiNYuwCxgL3ABcBrwMnBRmzWdQO37gTmTxr4BrE3La4F/aLvOSfVdASwDXp2uZop+kt+laEF3KfBCR+u/G/jrPutelP6eTgcWp7+zWS3Xfx6wLC2fBbye6mx1G7Q9E7gE2BMR+yLiV8DjwIqWa6piBbA+La8HrmmxluNExPPAzycNT1XzCuCRKGwFzu61om/LFPVPZQXweET8MiJ+QtEg95LGihtARByMiJfS8vvALmA+LW+DtkNgPvBW6fZEGhsFATwraZukNWns3Eht2NP1vNaqG9xUNY/Strk1TZfXlXbBOl2/pEXAxcALtLwN2g6Bft2OR+XrissiYhlwNXCLpCvaLqhmo7JtHgAuBJYCB4F70nhn65d0JrABuD0i3vukVfuM1f4e2g6BCWBB6fb5wIGWajkhEXEgXR8GnqaYah7qTdfS9eH2KhzYVDWPxLaJiEMRcSwiPgQe4qMpfyfrl3QqRQA8GhFPpeFWt0HbIfAisETSYkmnASuBjS3XNC1JZ0g6q7cMfBF4laL21Wm11cAz7VR4QqaqeSNwQzpCfSnwbm/K2iWT9pGvpdgOUNS/UtLpkhYDS4AfznR9ZZIEPAzsioh7S3e1uw3aPFpaOgL6OsXR27varmfAmi+gOPL8MrCzVzfwKWAL8Ea6PqftWifV/RjFlPl/Kf7L3DhVzRRT0X9O2+UVYKyj9f9rqm9H+tCcV1r/rlT/buDqDtT/+xTT+R3A9nRZ3vY28C8GzTLX9u6AmbXMIWCWOYeAWeYcAmaZcwiYZc4hYJY5h4BZ5hwCZpn7P7VMoJXXzXOoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(img)\n",
    "axs = plt.gca()\n",
    "print(proposal_)\n",
    "for i in range(len(proposal_)):\n",
    "    box = proposal_[i]\n",
    "    rec = patches.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1], facecolor='none', edgecolor='b')\n",
    "    axs.add_patch(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
