{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.layers as KL\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BatchNorm(KL.BatchNormalization):\n",
    "    def call(self, inputs, training=None):\n",
    "        return super(self.__class__, self).call(inputs, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def building_block(filters, block):\n",
    "    if block !=0 :\n",
    "        stride = 1\n",
    "    else:\n",
    "        stride = 2\n",
    "    def f(x):\n",
    "        y = KL.Conv2D(filters, (1,1), strides=stride)(x)\n",
    "        y = BatchNorm(axis=3)(y)\n",
    "        y = KL.Activation(\"relu\")(y)\n",
    "        \n",
    "        y = KL.Conv2D(filters, (3,3), padding=\"same\")(y)\n",
    "        y = BatchNorm(axis=3)(y)\n",
    "        y = KL.Activation(\"relu\")(y)\n",
    "        \n",
    "        y = KL.Conv2D(4*filters, (1,1))(y)\n",
    "        y = BatchNorm(axis=3)(y)\n",
    "        \n",
    "        if block == 0:\n",
    "            shorcut = KL.Conv2D(4*filters, (1,1), strides=stride)(x)\n",
    "            shorcut = BatchNorm(axis=3)(shorcut)\n",
    "        else:\n",
    "            shorcut = x\n",
    "        y = KL.Add()([y, shorcut])\n",
    "        y = KL.Activation(\"relu\")(y)\n",
    "        return y\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resNet_featureExtractor(inputs):\n",
    "    x = KL.Conv2D(64, (3,3), padding=\"same\")(inputs)\n",
    "    x = BatchNorm(axis=3)(x)\n",
    "    x = KL.Activation(\"relu\")(x)\n",
    "    \n",
    "    filters = 64\n",
    "    blocks = [6, 6, 6]\n",
    "    for i, block_num in enumerate(blocks):\n",
    "        for block_id in range(block_num):\n",
    "            x = building_block(filters, block_id)(x)\n",
    "        filters *= 2\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rpn_net(inputs, k):\n",
    "    shared_map = KL.Conv2D(256, (3,3), padding=\"same\")(inputs)\n",
    "    shared_map = KL.Activation(\"linear\")(shared_map)\n",
    "    rpn_class = KL.Conv2D(2*k, (1,1))(shared_map)\n",
    "    rpn_class = KL.Lambda(lambda x: tf.reshape(x, [tf.shape(x)[0],-1,2]))(rpn_class)\n",
    "    rpn_class = KL.Activation(\"linear\")(rpn_class)\n",
    "    rpn_prob = KL.Activation(\"softmax\")(rpn_class)\n",
    "    \n",
    "    y = KL.Conv2D(4*k, (1,1))(shared_map)\n",
    "    y = KL.Activation(\"linear\")(y)\n",
    "    rpn_bbox = KL.Lambda(lambda x: tf.reshape(x, [tf.shape(x)[0],-1,4]))(y)\n",
    "    return rpn_class, rpn_prob, rpn_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rpn_class_loss(rpn_match, rpn_class_logits):\n",
    "    ## rpn_match (None, 576, 1)\n",
    "    ## rpn_class_logits (None, 576, 2)\n",
    "    rpn_match = tf.squeeze(rpn_match, -1)\n",
    "    indices = tf.where(K.not_equal(rpn_match, 0))\n",
    "    anchor_class = K.cast(K.equal(rpn_match, 1), tf.int32)\n",
    "    rpn_class_logits = tf.gather_nd(rpn_class_logits, indices)     ### prediction\n",
    "    anchor_class = tf.gather_nd(anchor_class, indices)   ### target\n",
    "    loss = K.sparse_categorical_crossentropy(target=anchor_class, output=rpn_class_logits, from_logits=True)\n",
    "    loss = K.switch(tf.size(loss) > 0 , K.mean(loss), tf.constant(0.0))\n",
    "    return loss\n",
    "\n",
    "def batch_back(x, counts, num_rows):\n",
    "    outputs = []\n",
    "    for i in range(num_rows):\n",
    "        outputs.append(x[i, :counts[i]])\n",
    "    return tf.concat(outputs, axis=0)\n",
    "\n",
    "\n",
    "def rpn_bbox_loss(target_bbox, rpn_match, rpn_bbox):\n",
    "    rpn_match = tf.squeeze(rpn_match, -1)\n",
    "    indices = tf.where(K.equal(rpn_match, 1))\n",
    "    rpn_bbox = tf.gather_nd(rpn_bbox, indices)\n",
    "    batch_counts = K.sum(K.cast(K.equal(rpn_match, 1), tf.int32), axis=1)\n",
    "    target_bbox = batch_back(target_bbox, batch_counts, 20)\n",
    "    diff = K.abs(target_bbox - rpn_bbox)\n",
    "    less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "    loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "    loss = K.switch(tf.size(loss) > 0 , K.mean(loss), tf.constant(0.0))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_image = KL.Input(shape=[64,64,3], dtype=tf.float32)\n",
    "input_bboxes = KL.Input(shape=[None,4], dtype=tf.float32)\n",
    "input_class_ids = KL.Input(shape=[None],dtype=tf.int32)\n",
    "input_rpn_match = KL.Input(shape=[None, 1], dtype=tf.int32)\n",
    "input_rpn_bbox = KL.Input(shape=[None, 4], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = KL.Input((64, 64, 3))  # change\n",
    "fp = resNet_featureExtractor(x)\n",
    "rpn_class, rpn_prob, rpn_bbox = rpn_net(fp, 9)\n",
    "model = Model([x], [rpn_class, rpn_prob, rpn_bbox])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map = resNet_featureExtractor(input_image)\n",
    "rpn_class, rpn_prob, rpn_bbox = rpn_net(feature_map, 9)\n",
    "\n",
    "loss_rpn_match = KL.Lambda(lambda x: rpn_class_loss(*x), name=\"loss_rpn_match\")([input_rpn_match, rpn_class])\n",
    "\n",
    "loss_rpn_bbox = KL.Lambda(lambda x: rpn_bbox_loss(*x), name=\"loss_rpn_bbox\")([input_rpn_bbox, input_rpn_match, rpn_bbox])\n",
    "\n",
    "model = Model([input_image, input_bboxes, input_class_ids, input_rpn_match, input_rpn_bbox],\n",
    "              [rpn_class, rpn_prob, rpn_bbox, loss_rpn_match, loss_rpn_bbox])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "loss_lay1 = model.get_layer(\"loss_rpn_match\").output\n",
    "loss_lay2 = model.get_layer(\"loss_rpn_bbox\").output\n",
    "\n",
    "model.add_loss(tf.reduce_mean(loss_lay1))\n",
    "model.add_loss(tf.reduce_mean(loss_lay2))\n",
    "\n",
    "model.compile(loss=[None]*len(model.output), optimizer=keras.optimizers.SGD(lr=0.00005, momentum=0.9))\n",
    "\n",
    "model.metrics_names.append(\"loss_rpn_match\")\n",
    "model.metrics_tensors.append(tf.reduce_mean(loss_lay1, keep_dims=True))\n",
    "\n",
    "model.metrics_names.append(\"loss_rpn_bbox\")\n",
    "model.metrics_tensors.append(tf.reduce_mean(loss_lay2, keep_dims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import shapeData as dataSet\n",
    "from config import Config\n",
    "\n",
    "config = Config()\n",
    "dataset = dataSet([64,64], config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_Gen(dataset, num_batch, batch_size, config):\n",
    "    for _ in range(num_batch):\n",
    "        images = []\n",
    "        bboxes = []\n",
    "        class_ids = []\n",
    "        rpn_matchs = []\n",
    "        rpn_bboxes = []\n",
    "        for i in range(batch_size):\n",
    "            image, bbox, class_id, rpn_match, rpn_bbox, _ = data = dataset.load_data()\n",
    "            pad_num = config.max_gt_obj - bbox.shape[0]\n",
    "            pad_box = np.zeros((pad_num, 4))\n",
    "            pad_ids = np.zeros((pad_num, 1))\n",
    "            bbox = np.concatenate([bbox, pad_box], axis=0)\n",
    "            class_id = np.concatenate([class_id, pad_ids], axis=0)\n",
    "        \n",
    "            images.append(image)\n",
    "            bboxes.append(bbox)\n",
    "            class_ids.append(class_id)\n",
    "            rpn_matchs.append(rpn_match)\n",
    "            rpn_bboxes.append(rpn_bbox)\n",
    "        images = np.concatenate(images, 0).reshape(batch_size, config.image_size[0],config.image_size[1] , 3)\n",
    "        bboxes = np.concatenate(bboxes, 0).reshape(batch_size, -1 , 4)\n",
    "        class_ids = np.concatenate(class_ids, 0).reshape(batch_size, -1 )\n",
    "        rpn_matchs = np.concatenate(rpn_matchs, 0).reshape(batch_size, -1 , 1)\n",
    "        rpn_bboxes = np.concatenate(rpn_bboxes, 0).reshape(batch_size, -1 , 4)\n",
    "        yield [images, bboxes, class_ids, rpn_matchs, rpn_bboxes],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGen = data_Gen(dataset, 35000, 20, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#his = model.fit_generator(dataGen, steps_per_epoch=20, epochs=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.save_weights(\"model_material.h5\")\n",
    "model.load_weights(\"model_material.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def anchor_refinement(boxes, deltas):\n",
    "    boxes = tf.cast(boxes, tf.float32)\n",
    "    h = boxes[:, 2] - boxes[:, 0]\n",
    "    w = boxes[:, 3] - boxes[:, 1]\n",
    "    center_y = boxes[:, 0] + h / 2\n",
    "    center_x = boxes[:, 1] + w / 2\n",
    "\n",
    "    center_y += deltas[:, 0] * h\n",
    "    center_x += deltas[:, 1] * w\n",
    "    h *= tf.exp(deltas[:, 2])\n",
    "    w *= tf.exp(deltas[:, 3])\n",
    "    \n",
    "    y1 = center_y - h / 2\n",
    "    x1 = center_x - w / 2\n",
    "    y2 = center_y + h / 2\n",
    "    x2 = center_x + w / 2\n",
    "    boxes = tf.stack([y1, x1, y2, x2], axis=1)\n",
    "    return boxes\n",
    "    \n",
    "def boxes_clip(boxes, window):\n",
    "    wy1, wx1, wy2, wx2 = tf.split(window, 4)\n",
    "    y1, x1, y2, x2 = tf.split(boxes, 4, axis=1)\n",
    "    y1 = tf.maximum(tf.minimum(y1, wy2), wy1)\n",
    "    x1 = tf.maximum(tf.minimum(x1, wx2), wx1)\n",
    "    y2 = tf.maximum(tf.minimum(y2, wy2), wy1)\n",
    "    x2 = tf.maximum(tf.minimum(x2, wx2), wx1)\n",
    "    cliped = tf.concat([y1, x1, y2, x2], axis=1)\n",
    "    cliped.set_shape((cliped.shape[0], 4))\n",
    "    return cliped\n",
    "    \n",
    "def batch_slice(inputs, graph_fn, batch_size):\n",
    "    if not isinstance(inputs, list):\n",
    "        inputs = [inputs]\n",
    "    output = []\n",
    "    for i in range(batch_size):\n",
    "        inputs_slice = [x[i] for x in inputs]\n",
    "        output_slice = graph_fn(*inputs_slice)\n",
    "        if not isinstance(output_slice, (list, tuple)):\n",
    "            output_slice = [output_slice]\n",
    "        output.append(output_slice)\n",
    "    output = list(zip(*output))\n",
    "    result = [tf.stack(o, axis=0) for o in output]\n",
    "    if len(result)==1:\n",
    "        result = result[0]\n",
    "    return result\n",
    "\n",
    "import keras.engine as KE\n",
    "\n",
    "class proposal(KE.Layer):\n",
    "    def __init__(self, proposal_count, nms_thresh, anchors, batch_size, config=None, **kwargs):\n",
    "        super(proposal, self).__init__(**kwargs)\n",
    "        self.proposal_count = proposal_count\n",
    "        self.anchors = anchors\n",
    "        self.nms_thresh = nms_thresh\n",
    "        self.batch_size = batch_size\n",
    "        self.config = config\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        probs = inputs[0][:, :, 1]\n",
    "        deltas = inputs[1]\n",
    "        deltas = deltas * np.reshape(self.config.RPN_BBOX_STD_DEV, (1, 1, 4))\n",
    "        prenms_num = min(100, self.anchors.shape[0])\n",
    "        idxs = tf.nn.top_k(probs, prenms_num).indices\n",
    "        \n",
    "        probs = batch_slice([probs, idxs], lambda x,y:tf.gather(x, y), self.batch_size)\n",
    "        deltas = batch_slice([deltas, idxs], lambda x,y:tf.gather(x, y), self.batch_size)\n",
    "        anchors = batch_slice([idxs], lambda x:tf.gather(self.anchors,x), self.batch_size)\n",
    "        refined_boxes = batch_slice([anchors, deltas], lambda x,y:anchor_refinement(x,y), self.batch_size)\n",
    "        H,W = self.config.image_size[:2]\n",
    "        windows = np.array([0,0,H,W]).astype(np.float32)\n",
    "        cliped_boxes = batch_slice([refined_boxes], lambda x:boxes_clip(x, windows), self.batch_size)\n",
    "        normalized_boxes = cliped_boxes / np.array([H,W,H,W])\n",
    "        def nms(normalized_boxes, scores):\n",
    "            idxs_ = tf.image.non_max_suppression(normalized_boxes, scores, self.proposal_count, self.nms_thresh)\n",
    "            box = tf.gather(normalized_boxes, idxs_)\n",
    "            pad_num = tf.maximum(self.proposal_count - tf.shape(normalized_boxes)[0],0)\n",
    "            box = tf.pad(box, [(0,pad_num),(0,0)])\n",
    "            return box\n",
    "        proposal_ = batch_slice([normalized_boxes, probs], nms, self.batch_size)\n",
    "        return proposal_\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.proposal_count, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = next(dataGen)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = test_data[0]\n",
    "bboxes = test_data[1]\n",
    "class_ids = test_data[2]\n",
    "rpn_matchs = test_data[3]\n",
    "rpn_bboxes = test_data[4]\n",
    "\n",
    "\n",
    "rpn_class, rpn_prob, rpn_bbox, _, _ = \\\n",
    "                model.predict([images, bboxes, class_ids, rpn_matchs, rpn_bboxes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpn_class = tf.convert_to_tensor(rpn_class)\n",
    "rpn_prob = tf.convert_to_tensor(rpn_prob)\n",
    "rpn_bbox = tf.convert_to_tensor(rpn_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "anchors = utils.anchor_gen([8,8], ratios=config.ratios, scales=config.scales, rpn_stride=config.rpn_stride, \n",
    "                           anchor_stride = config.anchor_stride)\n",
    "\n",
    "\n",
    "proposals = proposal(proposal_count=16, nms_thresh=0.7, anchors=anchors, batch_size=20, config=config)([rpn_prob, rpn_bbox])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "proposals_ = sess.run(proposals) * 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "ix = random.sample(range(20), 1)[0]\n",
    "proposal_ = proposals_[ix]\n",
    "img = images[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFiCAYAAAAna2l5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYRERH/1/ywj00tdDMXIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f106b540a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(img)\n",
    "axs = plt.gca()\n",
    "\n",
    "for i in range(proposal_.shape[0]):\n",
    "    box = proposal_[i]\n",
    "    rec = patches.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1], facecolor='none', edgecolor='r')\n",
    "    axs.add_patch(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
